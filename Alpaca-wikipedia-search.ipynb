{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c516f055",
   "metadata": {},
   "source": [
    "\n",
    "# 🦙Llama-cpp users🦙\n",
    "## If you are just using llama-cpp then follow these steps\n",
    "\n",
    "The a folder containing the bin file should be located in the models folder \n",
    "\n",
    "Example: \"./models/Alpaca-7B-ggml-4bit-LoRA-merged/ggml-model-q4_0.bin\"\n",
    "## Install and Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "216c2668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting llama-cpp-python\n",
      "  Downloading llama_cpp_python-0.1.34.tar.gz (1.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from llama-cpp-python) (4.5.0)\n",
      "Building wheels for collected packages: llama-cpp-python\n",
      "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.1.34-cp310-cp310-linux_x86_64.whl size=138481 sha256=b7bf19c821ef39c0b6ba48494d59613ddc0927cd83d92a7afe1492db10fab30d\n",
      "  Stored in directory: /home/captdishwasher/.cache/pip/wheels/c3/df/54/e25ec8fe359db8240b51f3849e8b8de07ffc693f880ebf40c4\n",
      "Successfully built llama-cpp-python\n",
      "Installing collected packages: llama-cpp-python\n",
      "Successfully installed llama-cpp-python-0.1.34\n",
      "Requirement already satisfied: langchain in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (0.0.142)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<2,>=1 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (1.4.47)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/captdishwasher/.local/lib/python3.10/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from langchain) (4.0.2)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (0.5.7)\n",
      "Requirement already satisfied: gptcache>=0.1.7 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (0.1.13)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /home/captdishwasher/.local/lib/python3.10/site-packages (from langchain) (1.24.2)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: pydantic<2,>=1 in /home/captdishwasher/.local/lib/python3.10/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /home/captdishwasher/.local/lib/python3.10/site-packages (from langchain) (2.28.2)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/captdishwasher/.local/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.8.0)\n",
      "Requirement already satisfied: openai in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from gptcache>=0.1.7->langchain) (0.27.4)\n",
      "Requirement already satisfied: cachetools in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from gptcache>=0.1.7->langchain) (5.3.0)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from pydantic<2,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2022.12.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from SQLAlchemy<2,>=1->langchain) (2.0.2)\n",
      "Requirement already satisfied: packaging>=17.0 in /home/captdishwasher/.local/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (21.3)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: tqdm in /home/captdishwasher/.local/lib/python3.10/site-packages (from openai->gptcache>=0.1.7->langchain) (4.65.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /home/captdishwasher/miniconda3/envs/textgen/lib/python3.10/site-packages (from packaging>=17.0->marshmallow<4.0.0,>=3.3.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (3.0.9)\n"
     ]
    }
   ],
   "source": [
    "!pip install llama-cpp-python\n",
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f5c1334",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain import PromptTemplate, LLMChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb8478bd",
   "metadata": {},
   "source": [
    "# Select Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "83932f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. toolpaca-13b-native-ggml-model-q4_0\n",
      "2. Alpacino-13b-ggml\n",
      "3. llama-13b-pretrained-sft-do2-ggml-q4\n",
      "4. llama-13b-pretrained-dropout-ggml-q4_0\n",
      "5. gpt4all-j\n",
      "6. Alpaca13B\n",
      "7. vicuna-13B-1.1-GPTQ-4bit-128g-GGML\n",
      "8. llama-30b\n",
      "9. vicuna-13b-ggml-q4_0-delta-merged\n",
      "10. oasst-llama30b-ggml-q4\n",
      "11. GPT4-x-Alpaca-13B\n",
      "12. gpt4-alpaca-lora-30B-4bit-GGML\n",
      "13. llama-13b-ggml-q4_0\n",
      "Selected model binary: /media/captdishwasher/Samshmung/horenbergerb/llama/llama.cpp/models/vicuna-13B-1.1-GPTQ-4bit-128g-GGML/vicuna-13B-1.1-GPTQ-4bit-128g.GGML.bin\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama.cpp: loading model from /media/captdishwasher/Samshmung/horenbergerb/llama/llama.cpp/models/vicuna-13B-1.1-GPTQ-4bit-128g-GGML/vicuna-13B-1.1-GPTQ-4bit-128g.GGML.bin\n",
      "llama_model_load_internal: format     = ggjt v1 (latest)\n",
      "llama_model_load_internal: n_vocab    = 32000\n",
      "llama_model_load_internal: n_ctx      = 2048\n",
      "llama_model_load_internal: n_embd     = 5120\n",
      "llama_model_load_internal: n_mult     = 256\n",
      "llama_model_load_internal: n_head     = 40\n",
      "llama_model_load_internal: n_layer    = 40\n",
      "llama_model_load_internal: n_rot      = 128\n",
      "llama_model_load_internal: ftype      = 4 (mostly Q4_1, some F16)\n",
      "llama_model_load_internal: n_ff       = 13824\n",
      "llama_model_load_internal: n_parts    = 1\n",
      "llama_model_load_internal: model size = 13B\n",
      "llama_model_load_internal: ggml ctx size =  73.73 KB\n",
      "llama_model_load_internal: mem required  = 11749.65 MB (+ 3216.00 MB per state)\n",
      "llama_init_from_file: kv self size  = 3200.00 MB\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "model_dir = \"/media/captdishwasher/Samshmung/horenbergerb/llama/llama.cpp/models/\"\n",
    "import os\n",
    "# get a list of all folders in the models directory\n",
    "model_folders = [f for f in os.listdir(model_dir) if os.path.isdir(os.path.join(model_dir, f))]\n",
    "\n",
    "# print the list of model names with their index starting at 1\n",
    "for i, model_name in enumerate(model_folders):\n",
    "    print(f\"{i+1}. {model_name}\")\n",
    "\n",
    "# ask the user to select a model by number\n",
    "selected_index = int(input(\"Enter the number of the model to select: \")) - 1\n",
    "selected_model = model_folders[selected_index]\n",
    "\n",
    "# check if the selected model contains a .bin file and save the path if it does\n",
    "model_bin = None\n",
    "for file in os.listdir(os.path.join(model_dir, selected_model)):\n",
    "    if file.endswith(\".bin\"):\n",
    "        model_bin = os.path.join(model_dir, selected_model, file)\n",
    "        break\n",
    "\n",
    "if model_bin:\n",
    "    print(f\"Selected model binary: {model_bin}\")\n",
    "else:\n",
    "    print(\"No .bin file found in selected model directory.\")\n",
    "    \n",
    "llm = LlamaCpp(model_path=model_bin, n_ctx=2048, n_threads=7, temperature=0.65)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc3e44b",
   "metadata": {},
   "source": [
    "# Begginning of Langchain section\n",
    "I stole some of the code from [this colab](https://colab.research.google.com/drive/1VOwJpcZqOXag-ZXi-52ibOx6L5Pw-YJi#scrollTo=nu-AmhDLEK0h) that goes with [this video](https://www.youtube.com/watch?v=LbT1yp6quS8) by Patrick Loeber. I recommend subscribing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77708f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain import OpenAI, GoogleSearchAPIWrapper, LLMChain\n",
    "from typing import List, Union\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4b828f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which tools the agent can use to answer user queries\n",
    "search = GoogleSearchAPIWrapper(google_api_key='DUMMYKEY', google_cse_id='DUMMYKEY')\n",
    "tools = [\n",
    "    Tool(\n",
    "        name = \"Search\",\n",
    "        func=search.run,\n",
    "        description=\"useful for when you need to answer questions about current events\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "458230b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the base template\n",
    "template = \"\"\"User: Answer the following questions as best you can, but speaking as a pirate might speak. You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Answer using exactly the following format:\n",
    "\n",
    "```\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "```\n",
    "\n",
    "Your answers should always begin with \"Question:\".\n",
    "\n",
    "Assistant: Understood. I will answer further questions using exactly the provided format. My final answer will be formatted in pirate speak.\n",
    "User: {input}\n",
    "Assistant: {agent_scratchpad}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e826ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        return self.template.format(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "01afe8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    # This omits the `agent_scratchpad`, `tools`, and `tool_names` variables because those are generated dynamically\n",
    "    # This includes the `intermediate_steps` variable because that is needed\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6e68fa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action\\s*\\d*\\s*:(.*?)\\nAction\\s*\\d*\\s*Input\\s*\\d*\\s*:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "3a67130b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = CustomOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7542f804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM chain consisting of the LLM and a prompt\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0e0726d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_names = [tool.name for tool in tools]\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain, \n",
    "    output_parser=output_parser,\n",
    "    stop=[\"\\nObservation:\"], \n",
    "    allowed_tools=tool_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1aff6d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "2b9d1c7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m Question: How many people live in Canada as of 2023?\n",
      "Thought: I need to know the current population of Canada.\n",
      "Action: Search\n",
      "Action Input: \"Canadian population 2023\"\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2996.85 ms\n",
      "llama_print_timings:      sample time =    19.16 ms /    54 runs   (    0.35 ms per run)\n",
      "llama_print_timings: prompt eval time = 76356.40 ms /   220 tokens (  347.07 ms per token)\n",
      "llama_print_timings:        eval time = 28620.48 ms /    53 runs   (  540.01 ms per run)\n",
      "llama_print_timings:       total time = 105000.47 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3mThe current population of Canada is 38,662,830 as of Monday, April 17, 2023, based on Worldometer elaboration of the latest United Nations data. · Canada 2020 ... Mar 22, 2023 ... Record-high population growth in the year 2022. Canada's population was estimated at 39,566,248 on January 1, 2023, after a record population ... Mar 22, 2023 ... Total population grew by a record 1.05 million people to 39.57 million in the twelve months to Jan. 1, 2023, and about 96% of the rise was due ... 14 records ... Estimated number of persons by quarter of a year and by year, Canada, provinces and ... Geography, Q1 2022, Q2 2022, Q3 2022, Q4 2022, Q1 2023 ... Mar 22, 2023 ... The North American country documented an increase of more than 1 million citizens in 2022, bringing its population to more than 39.5 million, ... The current population of Canada in 2023 is 38,781,291, a 0.85% increase from 2022. The population of Canada in 2022 was 38,454,327, a 0.78% increase from 2021. Mar 17, 2023 ... Index to the latest information from the Census of Population. ... 2023. Census in Brief: Indigenous languages across Canada. Canada saw record population growth in 2022, with immigration accounting for the vast majority of the 1.05 ... Published 5:33 PM EDT, Wed March 22, 2023. Quarterly population estimate - Canada (Note) (January 1, 2023). 39,566,248. 0.7% increase · Consumer Price Index - Canada (February 2023). 5.2% increase. (12- ... 5 days ago ... Overall outbreak incidence has been stable since mid-January 2023. There continues to be variation in COVID-19 trends across provinces and ...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m38,662,830 is the current population of Canada as of 2023, with a slight increase from the previous year.\n",
      "Final Answer: Arrrr, 38,662,830 be the current population o' Canada as o' 2023, with a wee bit o' increase from the previous year.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =  2996.85 ms\n",
      "llama_print_timings:      sample time =    29.56 ms /    82 runs   (    0.36 ms per run)\n",
      "llama_print_timings: prompt eval time = 300777.62 ms /   853 tokens (  352.61 ms per token)\n",
      "llama_print_timings:        eval time = 48956.60 ms /    81 runs   (  604.40 ms per run)\n",
      "llama_print_timings:       total time = 349773.68 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Arrrr, 38,662,830 be the current population o' Canada as o' 2023, with a wee bit o' increase from the previous year.\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.run(\"How many people live in canada as of 2023?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
